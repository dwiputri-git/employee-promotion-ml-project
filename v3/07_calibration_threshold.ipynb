{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 07 - Calibration and Threshold Tuning (V3)\n",
        "\n",
        "- Calibrate finalists (Platt or Isotonic) with CV\n",
        "- Tune threshold (maximize F1 or enforce recall floor)\n",
        "- Evaluate on holdout test; save curves and confusion matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import (confusion_matrix, f1_score, precision_recall_curve, \n",
        "                             classification_report, brier_score_loss)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "INP = Path('../v3_data/employee_promotion_features.csv')\n",
        "ART = Path('../v3_artifacts'); ART.mkdir(exist_ok=True)\n",
        "\n",
        "TARGET = 'Promotion_Eligible'\n",
        "\n",
        "df = pd.read_csv(INP)\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "])\n",
        "\n",
        "# For demonstration: use a GB finalist with nominal params (replace with tuned params if available)\n",
        "base = GradientBoostingClassifier(random_state=42)\n",
        "pipe = Pipeline([('pre', pre), ('model', base)])\n",
        "\n",
        "cal = CalibratedClassifierCV(pipe, method='isotonic', cv=5)\n",
        "cal.fit(X_train, y_train)\n",
        "proba = cal.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Threshold tuning: maximize F1\n",
        "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
        "f1s = 2*prec*rec/(prec+rec + 1e-12)\n",
        "best_idx = int(np.nanargmax(f1s))\n",
        "best_thr = thr[max(best_idx-1, 0)] if best_idx < len(thr) else 0.5\n",
        "\n",
        "pred = (proba >= best_thr).astype(int)\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "print('Best threshold (F1):', best_thr)\n",
        "print('Brier:', brier_score_loss(y_test, proba))\n",
        "print('Confusion Matrix:\\n', cm)\n",
        "print('\\nReport:\\n', classification_report(y_test, pred, digits=3))\n",
        "\n",
        "# Save calibration curve\n",
        "prob_true, prob_pred = calibration_curve(y_test, proba, n_bins=10)\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.plot(prob_pred, prob_true, marker='o')\n",
        "plt.plot([0,1],[0,1],'--',color='gray')\n",
        "plt.title('Calibration Curve (Isotonic)')\n",
        "plt.xlabel('Predicted probability')\n",
        "plt.ylabel('True fraction positive')\n",
        "plt.tight_layout()\n",
        "plt.savefig(ART / 'calibration_curve.png', dpi=160)\n",
        "plt.close()\n",
        "\n",
        "# Save threshold\n",
        "with open(ART / 'best_threshold.json', 'w') as f:\n",
        "    json.dump({'best_threshold_f1': float(best_thr)}, f, indent=2)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
