{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08 - Explainability and Fairness (V3)\n",
        "\n",
        "- SHAP global and local explanations for finalist model\n",
        "- Fairness slice metrics (precision/recall/FPR/FNR) by categorical groups\n",
        "- Save plots and metrics CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "INP = Path('../v3_data/employee_promotion_features.csv')\n",
        "ART = Path('../v3_artifacts'); ART.mkdir(exist_ok=True)\n",
        "\n",
        "TARGET = 'Promotion_Eligible'\n",
        "GROUP = 'Current_Position_Level'  # slice attribute if available\n",
        "\n",
        "# Data\n",
        "df = pd.read_csv(INP)\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "])\n",
        "\n",
        "model = GradientBoostingClassifier(random_state=42)\n",
        "pipe = Pipeline([('pre', pre), ('model', model)])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# SHAP (tree explainer on underlying GB model after fit)\n",
        "# Get transformed training features for summary plot\n",
        "pre_fit = pipe.named_steps['pre']\n",
        "Xtr = pre_fit.transform(X_train)\n",
        "clf = pipe.named_steps['model']\n",
        "try:\n",
        "    explainer = shap.TreeExplainer(clf)\n",
        "    shap_values = explainer.shap_values(Xtr)\n",
        "    plt.figure()\n",
        "    shap.summary_plot(shap_values, Xtr, show=False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ART / 'shap_summary.png', dpi=160)\n",
        "    plt.close()\n",
        "except Exception as e:\n",
        "    print('SHAP failed with:', e)\n",
        "\n",
        "# Fairness metrics by GROUP (if exists)\n",
        "if GROUP in df.columns:\n",
        "    proba = pipe.predict_proba(X_test)[:, 1]\n",
        "    pred = (proba >= 0.5).astype(int)\n",
        "    rows = []\n",
        "    for g, idx in X_test.groupby(GROUP).groups.items():\n",
        "        yt, pt = y_test.loc[idx], pred[idx]\n",
        "        rows.append({\n",
        "            GROUP: g,\n",
        "            'precision': precision_score(yt, pt, zero_division=0),\n",
        "            'recall': recall_score(yt, pt, zero_division=0)\n",
        "        })\n",
        "    pd.DataFrame(rows).to_csv(ART / 'fairness_slice_metrics.csv', index=False)\n",
        "else:\n",
        "    print(f'Slice attribute {GROUP} not found; skipping fairness slices')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
