{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Model Pipeline Baselines (V3)\n",
        "\n",
        "- Train/test split (stratified)\n",
        "- ColumnTransformer (scale + encode)\n",
        "- Baselines: Majority (implicit), LogisticRegression(balanced), DecisionTree(balanced)\n",
        "- Metrics: Accuracy, Precision, Recall, F1 macro/weighted, ROC-AUC, PR-AUC, Brier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, average_precision_score, brier_score_loss)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "INP = Path('../v3_data/employee_promotion_features.csv')\n",
        "ART = Path('../v3_artifacts'); ART.mkdir(exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(INP)\n",
        "TARGET = 'Promotion_Eligible'\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "])\n",
        "\n",
        "candidates = {\n",
        "    'logreg': LogisticRegression(max_iter=2000, class_weight='balanced'),\n",
        "    'dt': DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, model in candidates.items():\n",
        "    pipe = Pipeline([('pre', pre), ('model', model)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    proba = pipe.predict_proba(X_test)[:, 1]\n",
        "    pred = (proba >= 0.5).astype(int)\n",
        "    rows.append({\n",
        "        'model': name,\n",
        "        'accuracy': accuracy_score(y_test, pred),\n",
        "        'precision': precision_score(y_test, pred),\n",
        "        'recall': recall_score(y_test, pred),\n",
        "        'f1_macro': f1_score(y_test, pred, average='macro'),\n",
        "        'f1_weighted': f1_score(y_test, pred, average='weighted'),\n",
        "        'rocauc': roc_auc_score(y_test, proba),\n",
        "        'prauc': average_precision_score(y_test, proba),\n",
        "        'brier': brier_score_loss(y_test, proba)\n",
        "    })\n",
        "\n",
        "res = pd.DataFrame(rows)\n",
        "res.to_csv(ART / 'baseline_metrics.csv', index=False)\n",
        "res\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
